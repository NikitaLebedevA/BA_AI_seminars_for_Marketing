{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "iQ5oSCLjLUzr",
      "metadata": {
        "id": "iQ5oSCLjLUzr"
      },
      "source": [
        "# Полный Data Science\n",
        "\n",
        "В этом ноутбуке мы решаем задачу **прогноза оттока клиентов (churn)** по табличным данным.\n",
        "\n",
        "Будем работать с датасетом наподобие *Telco Customer Churn*:\n",
        "- каждая строка — клиент телеком/подписочного сервиса,\n",
        "- признаки — характеристики клиента и его поведения (тариф, услуги, длительность, платежи...),\n",
        "- целевая переменная `Churn` — ушёл клиент (`Yes`) или остался (`No`).\n",
        "\n",
        "В рамках задания мы:\n",
        "1. Сформулируем бизнес-задачу и выберем метрики качества.\n",
        "2. Сделаем EDA и предобработку данных.\n",
        "3. Сгенерируем и отфильтруем признаки.\n",
        "4. Разобьём данные на train/val/test.\n",
        "5. Обучим и сравним модели:\n",
        "   - KNN,\n",
        "   - Logistic Regression,\n",
        "   - DecisionTree,\n",
        "   - RandomForest,\n",
        "   - LightGBM (градиентный бустинг).\n",
        "6. Подберём гиперпараметры (GridSearchCV) и оценим влияние на качество.\n",
        "7. Сделаем отбор признаков под конкретные модели.\n",
        "8. Протестируете лучшую(ие) модель(и) на test.\n",
        "9. Попробуем простой стэкинг моделей.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YwneOF8GLUzt",
      "metadata": {
        "id": "YwneOF8GLUzt"
      },
      "outputs": [],
      "source": [
        "# Базовые импорты\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n",
        "\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xfyPSXqkLUzu",
      "metadata": {
        "id": "xfyPSXqkLUzu"
      },
      "source": [
        "## 1. Загрузка данных и описание бизнес-задачи\n",
        "\n",
        "### Бизнес-задача\n",
        "\n",
        "Мы — менеджеры по продукту/маркетингу в подписочном сервисе (телеком, SaaS, онлайн-сервис).\n",
        "\n",
        "Наша цель — **прогнозировать отток клиентов (churn)**, чтобы:\n",
        "- заранее выделять \"группу риска\" и запускать кампании удержания,\n",
        "- оптимизировать бюджет на retention-активности,\n",
        "- оценивать влияние изменений продукта/тарифов на отток.\n",
        "\n",
        "### Выбор метрик качества\n",
        "\n",
        "Задача — бинарная классификация (`Churn = Yes/No`), при этом класс `Yes` (ушёл) обычно **редкий**.\n",
        "\n",
        "\n",
        "Какую метрику классификации будем использовать?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KbFSbajJLUzu",
      "metadata": {
        "id": "KbFSbajJLUzu"
      },
      "outputs": [],
      "source": [
        "# Загрузка датасета (путь при необходимости поменяйте)\n",
        "df = pd.read_csv(\"telco_churn.csv\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gHOmOqFiESO6",
      "metadata": {
        "id": "gHOmOqFiESO6"
      },
      "source": [
        "Нас интересует:\n",
        "- **Recall** по классу `Churn=Yes` — какую долю действительно уходящих клиентов мы ловим? (важно не пропустить тех, кого можно спасти)\n",
        "- **Precision** по `Churn=Yes` — какой процент среди отобранных нами \"рисковых\" клиентов реально уйдут? (важно не тратить бюджет на удержание тех, кто и так останется)\n",
        "- **F1-score** по `Churn=Yes` — баланс между Precision и Recall,\n",
        "- **ROC-AUC** — общая способность модели разделять уходящих и остающихся клиентов, независимо от порога.\n",
        "\n",
        "Дополнительно можем смотреть **accuracy**, но при сильном дисбалансе классов она менее информативна."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D3TaJcCtLUzu",
      "metadata": {
        "id": "D3TaJcCtLUzu"
      },
      "outputs": [],
      "source": [
        "# Общая информация о данных\n",
        "display(df.info())\n",
        "display(df.describe(include=\"all\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7yNMjK8NLUzv",
      "metadata": {
        "id": "7yNMjK8NLUzv"
      },
      "source": [
        "## 2. EDA\n",
        "\n",
        "Проверим:\n",
        "- распределение целевой переменной (баланс классов),\n",
        "- основные числовые признаки,\n",
        "- связи некоторых признаков с оттоком."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xSyNqV5eLUzv",
      "metadata": {
        "id": "xSyNqV5eLUzv"
      },
      "outputs": [],
      "source": [
        "# Распределение целевой переменной (Churn)\n",
        "plt.figure(figsize=(4,4))\n",
        "df[\"Churn\"].value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Распределение классов Churn\")\n",
        "plt.ylabel(\"Количество клиентов\")\n",
        "plt.show()\n",
        "\n",
        "df[\"Churn\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yx7ztKocLUzv",
      "metadata": {
        "id": "yx7ztKocLUzv"
      },
      "outputs": [],
      "source": [
        "# Пример: распределение ежемесячных платежей для ушедших/оставшихся\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(data=df, x=\"MonthlyCharges\", hue=\"Churn\", bins=30, kde=False, multiple=\"stack\")\n",
        "plt.title(\"MonthlyCharges по классам Churn\")\n",
        "plt.show()\n",
        "\n",
        "# Пример: завимость оттока от типа контракта\n",
        "plt.figure(figsize=(6,4))\n",
        "churn_by_contract = pd.crosstab(df[\"Contract\"], df[\"Churn\"], normalize=\"index\")[\"Yes\"].sort_values(ascending=False)\n",
        "churn_by_contract.plot(kind=\"bar\")\n",
        "plt.title(\"Доля оттока по типу контракта\")\n",
        "plt.ylabel(\"Доля Churn=Yes\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PFkYwX8ELUzv",
      "metadata": {
        "id": "PFkYwX8ELUzv"
      },
      "outputs": [],
      "source": [
        "# Пример: корреляции между числовыми признаками и оттоком\n",
        "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "corr = df[num_cols + [\"Churn\"]].copy()\n",
        "\n",
        "# Переведем Churn в 0/1 для корреляций\n",
        "corr[\"Churn\"] = (df[\"Churn\"] == \"Yes\").astype(int)\n",
        "corr_matrix = corr.corr()\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Корреляция числовых признаков и Churn\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CA_0qPzJLUzv",
      "metadata": {
        "id": "CA_0qPzJLUzv"
      },
      "source": [
        "## 3. Предобработка данных\n",
        "\n",
        "Типичные шаги:\n",
        "- удалить или обработать идентификаторы (например, `customerID`),\n",
        "- привести строковые числовые признаки к числовому типу (`TotalCharges` часто приходит как object),\n",
        "- обработать пропуски,\n",
        "- разделить признаки на числовые и категориальные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gjY_AGuULUzv",
      "metadata": {
        "id": "gjY_AGuULUzv"
      },
      "outputs": [],
      "source": [
        "# Удалим идентификатор, если он есть\n",
        "if \"customerID\" in df.columns:\n",
        "    df = df.drop(columns=[\"customerID\"])\n",
        "\n",
        "# Преобразуем TotalCharges в число, если это object\n",
        "if \"TotalCharges\" in df.columns and df[\"TotalCharges\"].dtype == \"object\":\n",
        "    df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"].replace(\" \", np.nan), errors=\"coerce\")\n",
        "\n",
        "# Посмотрим на пропуски\n",
        "df.isna().mean().sort_values(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CjE4Pw5SLUzw",
      "metadata": {
        "id": "CjE4Pw5SLUzw"
      },
      "outputs": [],
      "source": [
        "# Простая обработка пропусков:\n",
        "# - числовые: медиана\n",
        "# - категориальные: мода (самое частое значение)\n",
        "\n",
        "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "for col in num_cols:\n",
        "    median = df[col].median()\n",
        "    df[col] = df[col].fillna(median)\n",
        "\n",
        "for col in cat_cols:\n",
        "    mode = df[col].mode()[0]\n",
        "    df[col] = df[col].fillna(mode)\n",
        "\n",
        "df.isna().sum().sum()  # проверим, что пропусков больше нет"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "429PmZeBLUzw",
      "metadata": {
        "id": "429PmZeBLUzw"
      },
      "source": [
        "## 4. Генерация и первичная фильтрация признаков\n",
        "\n",
        "Примеры новых фич для задачи оттока:\n",
        "- `AvgCharges` = `TotalCharges` / `tenure` — средний чек клиента за месяц,\n",
        "- `IsLongTermContract` — флаг долгосрочного контракта (1/2 года),\n",
        "- биннинг `tenure` по группам.\n",
        "\n",
        "После генерации можем удалить \"подозрительно\" дублирующие признаки и те, что сложно использовать (например, почти константы)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HMsZmShyLUzw",
      "metadata": {
        "id": "HMsZmShyLUzw"
      },
      "outputs": [],
      "source": [
        "# Сгенерируем несколько новых признаков\n",
        "\n",
        "if \"tenure\" in df.columns and \"TotalCharges\" in df.columns:\n",
        "    df[\"AvgCharges\"] = df[\"TotalCharges\"] / df[\"tenure\"].replace(0, np.nan)\n",
        "    df[\"AvgCharges\"] = df[\"AvgCharges\"].fillna(df[\"MonthlyCharges\"])  # если tenure=0, используем MonthlyCharges\n",
        "\n",
        "# Флаг долгосрочного контракта\n",
        "if \"Contract\" in df.columns:\n",
        "    df[\"IsLongTermContract\"] = df[\"Contract\"].isin([\"One year\", \"Two year\"]).astype(int)\n",
        "\n",
        "# Биннинг tenure\n",
        "if \"tenure\" in df.columns:\n",
        "    df[\"TenureGroup\"] = pd.cut(\n",
        "        df[\"tenure\"],\n",
        "        bins=[0, 12, 24, 48, 60, np.inf],\n",
        "        labels=[\"0-12\", \"12-24\", \"24-48\", \"48-60\", \"60+\"],\n",
        "        include_lowest=True,\n",
        "    )\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ezzTgHt8LUzw",
      "metadata": {
        "id": "ezzTgHt8LUzw"
      },
      "outputs": [],
      "source": [
        "# Обновим списки числовых и категориальных признаков\n",
        "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "print(\"Числовые признаки:\", num_cols)\n",
        "print(\"Категориальные признаки:\", cat_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NN1M4apBLUzw",
      "metadata": {
        "id": "NN1M4apBLUzw"
      },
      "source": [
        "Для первичной фильтрации можно:\n",
        "- убрать признаки с почти одной категорией/одним значением (low variance - маленькой дисперсией),\n",
        "- убрать очевидные дублирующие признаки.\n",
        "\n",
        "Здесь оставим всё, кроме таргета (`Churn`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_D66ohYkLUzw",
      "metadata": {
        "id": "_D66ohYkLUzw"
      },
      "outputs": [],
      "source": [
        "target_col = \"Churn\"\n",
        "\n",
        "X = df.drop(columns=[target_col])\n",
        "y = (df[target_col] == \"Yes\").astype(int)\n",
        "\n",
        "X.shape, y.mean()  # размер и доля оттока"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WnwZSxsYLUzw",
      "metadata": {
        "id": "WnwZSxsYLUzw"
      },
      "source": [
        "## 5. Разбиение на train / val / test\n",
        "\n",
        "Сделаем разбиение 60% / 20% / 20% с учётом стратификации (сохранение доли таргета в каждом датасете) по оттоку.\n",
        "\n",
        "\n",
        "Мы уже знаем, зачем нужны Train/Test. Зачем же нужна val выборка? Ваши варианты?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-6kY_6zELUzw",
      "metadata": {
        "id": "-6kY_6zELUzw"
      },
      "outputs": [],
      "source": [
        "# Сначала отделим test 20%\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "# Теперь из оставшихся 80% выделим 20% под val → получится 60/20/20\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.25, random_state=RANDOM_STATE, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.mean())\n",
        "print(\"Val:  \", X_val.shape, y_val.mean())\n",
        "print(\"Test: \", X_test.shape, y_test.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6Ht0HqqvQrbk",
      "metadata": {
        "id": "6Ht0HqqvQrbk"
      },
      "source": [
        "Val (валидационная выборка, выборка для отладки) -  нужна для подбора гиперпараметров модели. Это настройки алгоритма, которые не выучиваются из данных напрямую (например, количество деревьев в случайном лесу).\n",
        "\n",
        "\n",
        "Тут наша основная задача: не подсматривать в тестовую выборку в процессе улучшения модели (по тестовой выборке уже финально принимаем решение по модели). Иначе - можно бесконечно подсматривать в тестовые данные и под них улучшать/подгонять модель, что может приводить к переобучению и на новых данных будет заметная потеря качества.\n",
        "При этом подбирать гиперпараметры на тренировочных данных - тоже плохо. Так как на тренировочных данных мы не можем ничего сказать про модель (по крайней мере, ничего хорошего)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yK77J4PALUzw",
      "metadata": {
        "id": "yK77J4PALUzw"
      },
      "source": [
        "## 6. Кодирование категориальных признаков и масштабирование числовых\n",
        "\n",
        "Сделаем one-hot кодирование категориальных признаков и масштабирование числовых.\n",
        "Чтобы упростить, используем `pd.get_dummies` и `StandardScaler` только для числовых колонок."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71xglWFGLUzw",
      "metadata": {
        "id": "71xglWFGLUzw"
      },
      "outputs": [],
      "source": [
        "# One-hot кодирование категориальных признаков\n",
        "X_train_enc = pd.get_dummies(X_train, drop_first=True)\n",
        "X_val_enc = pd.get_dummies(X_val, drop_first=True)\n",
        "X_test_enc = pd.get_dummies(X_test, drop_first=True)\n",
        "\n",
        "# Выровняем набор колонок (после get_dummies они могут отличаться)\n",
        "X_train_enc, X_val_enc = X_train_enc.align(X_val_enc, join=\"left\", axis=1, fill_value=0)\n",
        "X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join=\"left\", axis=1, fill_value=0)\n",
        "\n",
        "X_train_enc.shape, X_val_enc.shape, X_test_enc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gsY_pym5LUzx",
      "metadata": {
        "id": "gsY_pym5LUzx"
      },
      "outputs": [],
      "source": [
        "# Масштабируем числовые признаки (важно для KNN и логрегрессии)\n",
        "\n",
        "num_mask = X_train_enc.columns.str.contains(\"MonthlyCharges\") | X_train_enc.columns.str.contains(\"TotalCharges\") | X_train_enc.columns.str.contains(\"tenure\") | X_train_enc.columns.str.contains(\"AvgCharges\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = X_train_enc.copy()\n",
        "X_val_scaled = X_val_enc.copy()\n",
        "X_test_scaled = X_test_enc.copy()\n",
        "\n",
        "cols_to_scale = X_train_enc.columns[num_mask]\n",
        "\n",
        "X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train_enc[cols_to_scale])\n",
        "X_val_scaled[cols_to_scale] = scaler.transform(X_val_enc[cols_to_scale])\n",
        "X_test_scaled[cols_to_scale] = scaler.transform(X_test_enc[cols_to_scale])\n",
        "\n",
        "X_train_scaled.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SkEqhvY4LUzx",
      "metadata": {
        "id": "SkEqhvY4LUzx"
      },
      "source": [
        "## 7. Базовое обучение моделей и измерение времени\n",
        "\n",
        "Обучим базовые версии моделей:\n",
        "- KNN,\n",
        "- Logistic Regression,\n",
        "- DecisionTree,\n",
        "- RandomForest,\n",
        "- LightGBM.\n",
        "\n",
        "Для каждой модели измерим:\n",
        "- время обучения,\n",
        "- время предсказания на валидации,\n",
        "- ключевые метрики (accuracy, precision, recall, F1, ROC-AUC)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YrZQJRO1LUzx",
      "metadata": {
        "id": "YrZQJRO1LUzx"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(name, model, X_tr, y_tr, X_val, y_val):\n",
        "    print(f\"===== {name} =====\")\n",
        "    t0 = time.time()\n",
        "    model.fit(X_tr, y_tr)\n",
        "    t_train = time.time() - t0\n",
        "\n",
        "    t0 = time.time()\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    t_pred = time.time() - t0\n",
        "\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
        "        roc_auc = roc_auc_score(y_val, y_val_proba)\n",
        "    else:\n",
        "        roc_auc = np.nan\n",
        "\n",
        "    acc = accuracy_score(y_val, y_val_pred)\n",
        "    prec = precision_score(y_val, y_val_pred, zero_division=0)\n",
        "    rec = recall_score(y_val, y_val_pred, zero_division=0)\n",
        "    f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
        "\n",
        "    print(f\"Время обучения:  {t_train:.4f} c\")\n",
        "    print(f\"Время предсказания: {t_pred:.4f} c\")\n",
        "    print(f\"Accuracy:  {acc:.3f}\")\n",
        "    print(f\"Precision: {prec:.3f}\")\n",
        "    print(f\"Recall:    {rec:.3f}\")\n",
        "    print(f\"F1:        {f1:.3f}\")\n",
        "    print(f\"ROC-AUC:   {roc_auc:.3f}\")\n",
        "    print()\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"model\": model,\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"t_train\": t_train,\n",
        "        \"t_pred\": t_pred,\n",
        "    }\n",
        "results = [] # сюда будем записывать результаты работы моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1YuugIISk-a",
      "metadata": {
        "id": "b1YuugIISk-a"
      },
      "outputs": [],
      "source": [
        "# KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_res = evaluate_model(\"KNN\", knn, X_train_scaled, y_train, X_val_scaled, y_val)\n",
        "results.append(knn_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T2mJrzQBTMMd",
      "metadata": {
        "id": "T2mJrzQBTMMd"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter=200, C=1.0, random_state=42)\n",
        "log_reg_res = evaluate_model(\"LogisticRegression\", log_reg, X_train_scaled, y_train, X_val_scaled, y_val)\n",
        "results.append(log_reg_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vI8SQ1b5TgMW",
      "metadata": {
        "id": "vI8SQ1b5TgMW"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "results.append(evaluate_model(\"DecisionTree\", dt, X_train_enc, y_train, X_val_enc, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qy7c07NuTibG",
      "metadata": {
        "id": "qy7c07NuTibG"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=42, n_jobs=-1)\n",
        "results.append(evaluate_model(\"RandomForest\", rf, X_train_enc, y_train, X_val_enc, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AoziL_knTm2B",
      "metadata": {
        "id": "AoziL_knTm2B"
      },
      "outputs": [],
      "source": [
        "# LightGBM\n",
        "lgbm = LGBMClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=-1,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "results.append(evaluate_model(\"LightGBM\", lgbm, X_train_enc, y_train, X_val_enc, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SeW_aWOrLUzx",
      "metadata": {
        "id": "SeW_aWOrLUzx"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(results)[[\"name\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\", \"t_train\", \"t_pred\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5n1PviarLUzx",
      "metadata": {
        "id": "5n1PviarLUzx"
      },
      "source": [
        "## 8. Подбор гиперпараметров (GridSearchCV)\n",
        "\n",
        "Сделаем небольшие гриды, чтобы не ждать слишком долго, и нарисуем графики зависимости качества от ключевого гиперпараметра.\n",
        "\n",
        "### 8.1. KNN — подбираем `n_neighbors`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OLMgEbdyLUzx",
      "metadata": {
        "id": "OLMgEbdyLUzx"
      },
      "outputs": [],
      "source": [
        "k_values = [3, 5, 7, 9, 11, 15, 20, 25, 30, 35, 40, 50]\n",
        "knn_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "    y_val_pred = knn.predict(X_val_scaled)\n",
        "    f1 = f1_score(y_val, y_val_pred)\n",
        "    knn_scores.append(f1)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(k_values, knn_scores, marker=\"o\")\n",
        "plt.title(\"KNN: F1-score на валидации в зависимости от k\")\n",
        "plt.xlabel(\"k (число соседей)\")\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.show()\n",
        "\n",
        "best_k = k_values[int(np.argmax(knn_scores))]\n",
        "best_k"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y8SDGNdhLUzx",
      "metadata": {
        "id": "Y8SDGNdhLUzx"
      },
      "source": [
        "### 8.2. DecisionTree — подбираем `max_depth`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CzIAbqkkLUzy",
      "metadata": {
        "id": "CzIAbqkkLUzy"
      },
      "outputs": [],
      "source": [
        "depth_values = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, None]\n",
        "dt_scores = []\n",
        "\n",
        "for d in depth_values:\n",
        "    dt = DecisionTreeClassifier(max_depth=d, random_state=RANDOM_STATE)\n",
        "    dt.fit(X_train_enc, y_train)\n",
        "    y_val_pred = dt.predict(X_val_enc)\n",
        "    f1 = f1_score(y_val, y_val_pred)\n",
        "    dt_scores.append(f1)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "labels = [str(d) for d in depth_values]\n",
        "plt.plot(labels, dt_scores, marker=\"o\")\n",
        "plt.title(\"DecisionTree: F1-score на валидации в зависимости от max_depth\")\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.show()\n",
        "\n",
        "depth_values[int(np.argmax(dt_scores))]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fh8O9PCeLUzy",
      "metadata": {
        "id": "fh8O9PCeLUzy"
      },
      "source": [
        "### 8.3. RandomForest — подбираем `n_estimators` и `max_depth` (через GridSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C6HST3ghLUzy",
      "metadata": {
        "id": "C6HST3ghLUzy"
      },
      "outputs": [],
      "source": [
        "param_grid_rf = {\n",
        "    \"n_estimators\": [50, 75, 100, 125, 150, 175, 200, 250],\n",
        "    \"max_depth\": [2, 3, 5, 7, 9],\n",
        "}\n",
        "\n",
        "rf_base = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
        "\n",
        "grid_rf = GridSearchCV(\n",
        "    rf_base,\n",
        "    param_grid_rf,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        ")\n",
        "grid_rf.fit(X_train_enc, y_train)\n",
        "\n",
        "print(\"Лучшие параметры RF:\", grid_rf.best_params_)\n",
        "print(\"Лучший F1 (cv):\", grid_rf.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dXprIRQtLUzy",
      "metadata": {
        "id": "dXprIRQtLUzy"
      },
      "source": [
        "### 8.4. LightGBM — подбираем `n_estimators` и `num_leaves` (GridSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aBftBKwFLUzy",
      "metadata": {
        "id": "aBftBKwFLUzy"
      },
      "outputs": [],
      "source": [
        "param_grid_lgbm = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"num_leaves\": [15, 31, 63],\n",
        "}\n",
        "\n",
        "lgbm_base = LGBMClassifier(\n",
        "    learning_rate=0.05,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "grid_lgbm = GridSearchCV(\n",
        "    lgbm_base,\n",
        "    param_grid_lgbm,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        ")\n",
        "grid_lgbm.fit(X_train_enc, y_train)\n",
        "\n",
        "print(\"Лучшие параметры LGBM:\", grid_lgbm.best_params_)\n",
        "print(\"Лучший F1 (cv):\", grid_lgbm.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_phKFE3gLUzy",
      "metadata": {
        "id": "_phKFE3gLUzy"
      },
      "source": [
        "### 8.5. Logistic Regression — подбор `C` (силы регуляризации)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zhjWv_-bLUzy",
      "metadata": {
        "id": "zhjWv_-bLUzy"
      },
      "outputs": [],
      "source": [
        "param_grid_log = {\"C\": [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
        "\n",
        "log_base = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
        "\n",
        "grid_log = GridSearchCV(\n",
        "    log_base,\n",
        "    param_grid_log,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "grid_log.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Лучшие параметры LogReg:\", grid_log.best_params_)\n",
        "print(\"Лучший F1 (cv):\", grid_log.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LTL4AMt3LUzy",
      "metadata": {
        "id": "LTL4AMt3LUzy"
      },
      "source": [
        "## 9. Отбор признаков под конкретные модели\n",
        "\n",
        "Для деревьев, лесов и бустинга можно использовать **важность признаков (feature importance)**.\n",
        "\n",
        "Сделаем, например, отбор топ-20 признаков для LightGBM и RandomForest, и обучим модели только на них."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nv_qojljLUzy",
      "metadata": {
        "id": "nv_qojljLUzy"
      },
      "outputs": [],
      "source": [
        "# Обучим лучшие модели RF и LGBM на всех признаках\n",
        "best_rf = grid_rf.best_estimator_\n",
        "best_rf.fit(X_train_enc, y_train)\n",
        "\n",
        "best_lgbm = grid_lgbm.best_estimator_\n",
        "best_lgbm.fit(X_train_enc, y_train)\n",
        "\n",
        "# Возьмем важности признаков из LGBM\n",
        "feat_imp = pd.Series(best_lgbm.feature_importances_, index=X_train_enc.columns)\n",
        "feat_imp = feat_imp.sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "feat_imp.head(20).plot(kind=\"bar\")\n",
        "plt.title(\"LightGBM: топ-20 признаков по важности\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "top_features = feat_imp.head(20).index.tolist()\n",
        "len(top_features), top_features[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gLIlwMjuLUzz",
      "metadata": {
        "id": "gLIlwMjuLUzz"
      },
      "outputs": [],
      "source": [
        "# Сформируем выборки только с топ-20 признаков\n",
        "X_train_top = X_train_enc[top_features]\n",
        "X_val_top = X_val_enc[top_features]\n",
        "X_test_top = X_test_enc[top_features]\n",
        "\n",
        "# Переобучим LGBM и RF на топ-20\n",
        "best_rf_top = grid_rf.best_estimator_\n",
        "best_rf_top.fit(X_train_top, y_train)\n",
        "y_val_pred_rf_top = best_rf_top.predict(X_val_top)\n",
        "f1_rf_top = f1_score(y_val, y_val_pred_rf_top)\n",
        "\n",
        "best_lgbm_top = grid_lgbm.best_estimator_\n",
        "best_lgbm_top.fit(X_train_top, y_train)\n",
        "y_val_pred_lgbm_top = best_lgbm_top.predict(X_val_top)\n",
        "f1_lgbm_top = f1_score(y_val, y_val_pred_lgbm_top)\n",
        "\n",
        "print(\"F1 RF (топ-20 признаков):\", f1_rf_top)\n",
        "print(\"F1 LGBM (топ-20 признаков):\", f1_lgbm_top)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YzJ2gYq7LUzz",
      "metadata": {
        "id": "YzJ2gYq7LUzz"
      },
      "source": [
        "## 10. Финальное тестирование на `test`\n",
        "\n",
        "Выберем 1–2 лучшие модели по F1/ROC-AUC на валидации и протестируем их на `test`.\n",
        "\n",
        "Здесь в качестве примера возьмём:\n",
        "- лучшую логистическую регрессию (grid_log.best_estimator_),\n",
        "- LightGBM на топ-20 признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y5AfwstMLUz6",
      "metadata": {
        "id": "Y5AfwstMLUz6"
      },
      "outputs": [],
      "source": [
        "# Лучшая логистическая регрессия\n",
        "final_log = grid_log.best_estimator_\n",
        "final_log.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_test_pred_log = final_log.predict(X_test_scaled)\n",
        "y_test_proba_log = final_log.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(\"=== LogisticRegression (test) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_log))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_log))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_log))\n",
        "print(\"F1:\", f1_score(y_test, y_test_pred_log))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_log))\n",
        "\n",
        "cm_log = confusion_matrix(y_test, y_test_pred_log)\n",
        "sns.heatmap(cm_log, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"LogReg: матрица ошибок (test)\")\n",
        "plt.xlabel(\"Предсказанный класс\")\n",
        "plt.ylabel(\"Истинный класс\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C16sp7C3LUz7",
      "metadata": {
        "id": "C16sp7C3LUz7"
      },
      "outputs": [],
      "source": [
        "# Лучший LightGBM на топ-20 признаков\n",
        "final_lgbm = best_lgbm_top\n",
        "\n",
        "y_test_pred_lgbm = final_lgbm.predict(X_test_top)\n",
        "y_test_proba_lgbm = final_lgbm.predict_proba(X_test_top)[:, 1]\n",
        "\n",
        "print(\"=== LightGBM (test, топ-20 признаков) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_lgbm))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_lgbm))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_lgbm))\n",
        "print(\"F1:\", f1_score(y_test, y_test_pred_lgbm))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_lgbm))\n",
        "\n",
        "cm_lgbm = confusion_matrix(y_test, y_test_pred_lgbm)\n",
        "sns.heatmap(cm_lgbm, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.title(\"LightGBM: матрица ошибок (test)\")\n",
        "plt.xlabel(\"Предсказанный класс\")\n",
        "plt.ylabel(\"Истинный класс\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_KPf5eBXLUz7",
      "metadata": {
        "id": "_KPf5eBXLUz7"
      },
      "source": [
        "## 11. Попытка стэкинга (Stacking)\n",
        "\n",
        "Скомбинируем несколько моделей (например, логистическую регрессию, RandomForest и LightGBM) в **стэкинг**:\n",
        "- базовые модели дают свои прогнозы,\n",
        "- метамодель (ещё одна логистическая регрессия) учится комбинировать их предсказания."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lzZ0EvG9LUz7",
      "metadata": {
        "id": "lzZ0EvG9LUz7"
      },
      "outputs": [],
      "source": [
        "base_estimators = [\n",
        "    (\"logreg\", grid_log.best_estimator_),\n",
        "    (\"rf\", grid_rf.best_estimator_),\n",
        "    (\"lgbm\", grid_lgbm.best_estimator_),\n",
        "]\n",
        "\n",
        "stack_clf = StackingClassifier(\n",
        "    estimators=base_estimators,\n",
        "    final_estimator=LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "# Для простоты используем enc-признаки (без урезания до топ-20)\n",
        "stack_clf.fit(X_train_enc, y_train)\n",
        "\n",
        "y_val_pred_stack = stack_clf.predict(X_val_enc)\n",
        "y_val_proba_stack = stack_clf.predict_proba(X_val_enc)[:, 1]\n",
        "\n",
        "print(\"=== Stacking (val) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred_stack))\n",
        "print(\"Precision:\", precision_score(y_val, y_val_pred_stack))\n",
        "print(\"Recall:\", recall_score(y_val, y_val_pred_stack))\n",
        "print(\"F1:\", f1_score(y_val, y_val_pred_stack))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_val, y_val_proba_stack))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o8DBgGLkLUz7",
      "metadata": {
        "id": "o8DBgGLkLUz7"
      },
      "outputs": [],
      "source": [
        "# Оценим стэкинг на test\n",
        "y_test_pred_stack = stack_clf.predict(X_test_enc)\n",
        "y_test_proba_stack = stack_clf.predict_proba(X_test_enc)[:, 1]\n",
        "\n",
        "print(\"=== Stacking (test) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_stack))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_stack))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_stack))\n",
        "print(\"F1:\", f1_score(y_test, y_test_pred_stack))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_stack))\n",
        "\n",
        "cm_stack = confusion_matrix(y_test, y_test_pred_stack)\n",
        "sns.heatmap(cm_stack, annot=True, fmt=\"d\", cmap=\"Purples\")\n",
        "plt.title(\"Stacking: матрица ошибок (test)\")\n",
        "plt.xlabel(\"Предсказанный класс\")\n",
        "plt.ylabel(\"Истинный класс\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f20acb",
      "metadata": {},
      "source": [
        "Если более простая модель (как тут - логистическая регрессия) дает результат не сильно хуже продвинутых моделей, то не нужно усложнять.\n",
        "\n",
        "Это плюс к:\n",
        "- Стабильности модели\n",
        "- Простоте внедрения модели\n",
        "- Возможности интерпретации результатов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lCf0K_BZLUz7",
      "metadata": {
        "id": "lCf0K_BZLUz7"
      },
      "source": [
        "## Заключение\n",
        "\n",
        "- Мы сравнили несколько моделей от простых (логистическая регрессия) до более сложных (лес, бустинг, стэкинг).\n",
        "- Оценивали их по метрикам, важным для бизнеса: Recall/Precision/F1, ROC-AUC.\n",
        "- Посмотрели на важность признаков и влияние отбора фич.\n",
        "- Собрали ансамбль (стэкинг) и проверили, даёт ли он выигрыш на тестовой выборке.\n",
        "\n",
        "Дальше можно экспериментировать:\n",
        "- менять метрики оптимизации (например, на ROC-AUC или PR-AUC),\n",
        "- тестировать другие модели,\n",
        "- внедрять cost-sensitive подход (учитывать стоимость ошибок отдельно для FP и FN)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
